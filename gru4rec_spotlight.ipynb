{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmrYwA6luyB",
        "outputId": "060c08e2-19f0-459f-d5c1-a54825ad3430"
      },
      "source": [
        "!git clone https://github.com/maciejkula/spotlight.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'spotlight'...\n",
            "remote: Enumerating objects: 3396, done.\u001b[K\n",
            "remote: Total 3396 (delta 0), reused 0 (delta 0), pack-reused 3396\u001b[K\n",
            "Receiving objects: 100% (3396/3396), 9.01 MiB | 1000.00 KiB/s, done.\n",
            "Resolving deltas: 100% (2234/2234), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojNZb-QTlx_O",
        "outputId": "1191288b-eb0e-4fc2-8f95-80027da2c018"
      },
      "source": [
        "!cd spotlight/ && pip install ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/spotlight\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spotlight==0.1.6) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->spotlight==0.1.6) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->spotlight==0.1.6) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->spotlight==0.1.6) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->spotlight==0.1.6) (3.7.4.3)\n",
            "Building wheels for collected packages: spotlight\n",
            "  Building wheel for spotlight (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spotlight: filename=spotlight-0.1.6-cp36-none-any.whl size=33921 sha256=8778d5381b784d23e942ba12564d522588e9e8eceeb70135358d0b89873f87cd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-imu1oazg/wheels/aa/35/94/c1f256fcf5e8f90a60a6733fdcc982ecbb2d249e1868cefb98\n",
            "Successfully built spotlight\n",
            "Installing collected packages: spotlight\n",
            "Successfully installed spotlight-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfzdAPrug0d1"
      },
      "source": [
        "import hashlib\r\n",
        "import json\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import sys\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.model_selection import ParameterSampler\r\n",
        "from spotlight.datasets.movielens import get_movielens_dataset\r\n",
        "from spotlight.cross_validation import user_based_train_test_split\r\n",
        "from spotlight.sequence.implicit import ImplicitSequenceModel\r\n",
        "from spotlight.sequence.representations import LSTMNet\r\n",
        "from spotlight.evaluation import sequence_mrr_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SRPJBEe3n_p"
      },
      "source": [
        "class GRU(nn.Module):\r\n",
        "    def __init__(self, num_items, embedding_dim=32):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\r\n",
        "\r\n",
        "        self.item_biases = nn.Embedding(num_items, 1)\r\n",
        "\r\n",
        "        self.gru = nn.GRU(batch_first=True,\r\n",
        "                          input_size=embedding_dim,\r\n",
        "                          hidden_size=embedding_dim,\r\n",
        "                          num_layers=3,\r\n",
        "                          dropout=0.5)\r\n",
        "\r\n",
        "    def user_representation(self, item_sequences):\r\n",
        "        # Make the embedding dimension the channel dimension\r\n",
        "        embeds = self.item_embeddings(item_sequences).permute(0, 2, 1)\r\n",
        "        # Add a trailing dimension of 1\r\n",
        "        embeds = embeds.unsqueeze(3)\r\n",
        "        # Pad it with zeros from left\r\n",
        "        embeds = F.pad(embeds, (0, 0, 1, 0)).squeeze(3)\r\n",
        "        embeds = embeds.permute(0, 2, 1)\r\n",
        "\r\n",
        "        user_representations, _ = self.gru(embeds)\r\n",
        "        user_representations = user_representations.permute(0, 2, 1)\r\n",
        "\r\n",
        "        return user_representations[..., :-1], user_representations[..., -1]\r\n",
        "\r\n",
        "    def forward(self, user_representations, targets):\r\n",
        "        target_embedding = (self.item_embeddings(targets)\r\n",
        "                            .permute(0, 2, 1)\r\n",
        "                            .squeeze())\r\n",
        "        target_bias = self.item_biases(targets).squeeze()\r\n",
        "\r\n",
        "        dot = ((user_representations * target_embedding)\r\n",
        "               .sum(1)\r\n",
        "               .squeeze())\r\n",
        "\r\n",
        "        return dot + target_bias"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjV11yQX5TP8"
      },
      "source": [
        "max_sequence_length = 7\r\n",
        "min_sequence_length = None\r\n",
        "step_size = 1\r\n",
        "random_state = np.random.RandomState(100)\r\n",
        "\r\n",
        "dataset = get_movielens_dataset('1M')\r\n",
        "\r\n",
        "train, rest = user_based_train_test_split(dataset,\r\n",
        "                                            random_state=random_state)\r\n",
        "test, validation = user_based_train_test_split(rest,\r\n",
        "                                                test_percentage=0.5,\r\n",
        "                                                random_state=random_state)\r\n",
        "train = train.to_sequence(max_sequence_length=max_sequence_length,\r\n",
        "                            min_sequence_length=min_sequence_length,\r\n",
        "                            step_size=step_size)\r\n",
        "test = test.to_sequence(max_sequence_length=max_sequence_length,\r\n",
        "                        min_sequence_length=min_sequence_length,\r\n",
        "                        step_size=step_size)\r\n",
        "validation = validation.to_sequence(max_sequence_length=max_sequence_length,\r\n",
        "                                    min_sequence_length=min_sequence_length,\r\n",
        "                                    step_size=step_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkKLiirv2j3K",
        "outputId": "0080435f-e1a6-4dab-bb89-bae76b9df40f"
      },
      "source": [
        "#net = LSTMNet(train.num_items,\r\n",
        "#             embedding_dim=100)\r\n",
        "\r\n",
        "net = GRU(train.num_items,\r\n",
        "          embedding_dim=32)\r\n",
        "\r\n",
        "model = ImplicitSequenceModel(loss='bpr',\r\n",
        "                              representation=net,\r\n",
        "                              batch_size=128,\r\n",
        "                              learning_rate=5e-3,\r\n",
        "                              l2=1e-5,\r\n",
        "                              n_iter=15,\r\n",
        "                              use_cuda=torch.cuda.is_available(),\r\n",
        "                              random_state=random_state)\r\n",
        "\r\n",
        "model.fit(train, verbose=True)\r\n",
        "\r\n",
        "(sequence_mrr_score(model, test).mean(), sequence_mrr_score(model, validation).mean())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.2017378723654667\n",
            "Epoch 1: loss 0.19739369838977944\n",
            "Epoch 2: loss 0.19701408993360622\n",
            "Epoch 3: loss 0.19754002839445783\n",
            "Epoch 4: loss 0.1973850923305688\n",
            "Epoch 5: loss 0.19746466446712507\n",
            "Epoch 6: loss 0.1973836047475279\n",
            "Epoch 7: loss 0.19762609945662193\n",
            "Epoch 8: loss 0.1972320837966937\n",
            "Epoch 9: loss 0.1974905374377419\n",
            "Epoch 10: loss 0.19742278506160257\n",
            "Epoch 11: loss 0.19743469977797456\n",
            "Epoch 12: loss 0.19734470864485856\n",
            "Epoch 13: loss 0.19716169162454933\n",
            "Epoch 14: loss 0.1973626666300219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.013560227251241503, 0.013796930220500242)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf7gwb554XzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}